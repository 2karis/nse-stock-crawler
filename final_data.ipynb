{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import mechanicalsoup\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scrapper():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.browser = mechanicalsoup.StatefulBrowser()\n",
    "\n",
    "    def login(self):\n",
    "        self.browser.open(self.config['login'])\n",
    "        self.browser.select_form(nr=0)\n",
    "        self.browser['txtLogin'] = self.config['username']\n",
    "        self.browser['txtPassword'] = self.config['password']\n",
    "        self.browser.submit_selected()\n",
    "        print(\"logging in\")\n",
    "        self.check_password()\n",
    "\n",
    "\n",
    "    def api_post(self, link, data):\n",
    "        r = requests.post(link, data=json.dumps(data))\n",
    "        print(r)\n",
    "\n",
    "    def password_generator(self, size=8, chars=string.ascii_lowercase + string.digits):\n",
    "        return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "    def write_password(self, password):\n",
    "        self.config[\"password\"] = password\n",
    "\n",
    "        with open(\"config.json\", \"w\") as jsonFile:\n",
    "            json.dump(self.config, jsonFile, indent=4, sort_keys=True)\n",
    "\n",
    "    def check_password(self):\n",
    "    \n",
    "        page = self.browser.get_current_page()\n",
    "        soup = BeautifulSoup(str(page), 'lxml')\n",
    "        #print(soup)\n",
    "        # if this is the change password page\n",
    "        if soup.title.text == '\\r\\n\\tChange Password\\r\\n':\n",
    "            # generate new password\n",
    "            new_password = self.password_generator()\n",
    "            # save to file\n",
    "            self.write_password(new_password)\n",
    "            self.browser.select_form(nr=0)\n",
    "            self.browser['txtLoginID'] = self.config['username']\n",
    "            self.browser['txtCurrPass'] = self.config['password']\n",
    "            self.browser['txtNewPass'] = new_password\n",
    "            self.browser['txtConfirmPass'] = new_password\n",
    "            self.browser.submit_selected()\n",
    "            print('password updated to ', new_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for rich.co.ke\n",
    "class rich_data(scrapper):\n",
    "    def __init__(self, c):\n",
    "        super().__init__(c)\n",
    "        print(\"rich scapper initialized\")\n",
    "        \n",
    "    def crawl_data(self):\n",
    "        browser = browser = mechanicalsoup.StatefulBrowser()\n",
    "        #use config for rich data\n",
    "        browser.open(\"http://www.rich.co.ke/rcdata/nsestocks.php\")\n",
    "        page = browser.get_current_page()\n",
    "        soup = BeautifulSoup(str(page), 'lxml')\n",
    "\n",
    "        #skip straight to the table we want and pull all the rows\n",
    "        rich_data = soup.body.find_all('table')[16].find_all(\"tr\")\n",
    "\n",
    "        #remove the first row cause its just the heading\n",
    "        rich_data.pop(0)\n",
    "        final_data = []\n",
    "\n",
    "        #add the data to a list as text\n",
    "        for tr in rich_data:\n",
    "            td = tr.find_all(\"td\")\n",
    "            final_data.append({\"stock\":str(td[1].get_text()),#name of company\n",
    "                               \"previous\":str(td[2].get_text()),\n",
    "                               \"current\":str(td[3].get_text()),\n",
    "                               \"percentage_change\":str(td[4].get_text()),\n",
    "                               \"volume\":str(td[6].get_text())\n",
    "                              })\n",
    "        return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wazua_data(scrapper):\n",
    "    def __init__(self, c):\n",
    "        super().__init__(c)\n",
    "        print(\"wazua scapper initialized\")\n",
    "    def crawl_data(self):\n",
    "        browser = browser = mechanicalsoup.StatefulBrowser()\n",
    "        browser.open(\"http://www.wazua.co.ke/investor/latestprices.aspx\")\n",
    "        page = browser.get_current_page()\n",
    "        soup = BeautifulSoup(str(page), 'lxml')\n",
    "\n",
    "        #skip straight to table we need\n",
    "        data = soup.body.find_all('table')[37].find_all(\"tr\")\n",
    "\n",
    "        #remove the first row cause its just the heading\n",
    "        data.pop(0)\n",
    "        final_data = []\n",
    "\n",
    "        #somethimg\n",
    "        for tr in data:\n",
    "            td = tr.find_all(\"td\")\n",
    "\n",
    "            #add the data to a list as text and remove \\n characters with replace()\n",
    "            final_data.append({\"title\":str(td[0].get_text().replace(\"\\n\",\"\")),\n",
    "                               \"price\":str(td[1].get_text().replace(\"\\n\",\"\")),\n",
    "                               \"volume\":str(td[2].get_text().replace(\"\\n\",\"\")),\n",
    "\n",
    "                               #hopefully they'll add some more useful info than this\n",
    "                               #str(td[3].get_text()),\n",
    "                               #str(td[4].get_text())\n",
    "                              })\n",
    "        return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_sdarr = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ticker_data(scrapper):\n",
    "    def __init__(self, c):\n",
    "        super().__init__(c)\n",
    "        print(\"ticker scapper initialized\")\n",
    "\n",
    "        \n",
    "    def crawl_data(self):\n",
    "        self.login()\n",
    "        self.browser.open(self.config['ticker'])\n",
    "        page = self.browser.get_current_page()\n",
    "        soup = BeautifulSoup(str(page), 'lxml')\n",
    "        \n",
    "        tickers=[]\n",
    "        if(soup.find(\"div\", {\"class\": \"CSPLTickerContainer\"})):\n",
    "            div = soup.find(\"div\", {\"class\": \"CSPLTickerContainer\"})\n",
    "            ul =  div.find(\"ul\")\n",
    "            li =  ul.find(\"li\")\n",
    "            \n",
    "\n",
    "            for li in ul:\n",
    "                combo = li.text.split('|', 1)[0]\n",
    "                security_price, change = combo.split(' ')\n",
    "                security = re.split('(\\d+)',security_price)\n",
    "                price = ''.join(security[1:4])\n",
    "                #items.append([security[0] ,price , change])\n",
    "                tickers.append({'security': security[0],\n",
    "                                'price': price,\n",
    "                                'price_change': change})\n",
    "\n",
    "        return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class market_data(scrapper):\n",
    "    def __init__(self, c):\n",
    "        super().__init__(c)\n",
    "        print(\"market scapper initialized\")\n",
    "\n",
    "        \n",
    "    def crawl_data(self):\n",
    "        self.login()\n",
    "        self.browser.open(self.config['market'])\n",
    "        page = self.browser.get_current_page()\n",
    "        soup = BeautifulSoup(str(page), 'lxml')\n",
    "        \n",
    "        markets=[]\n",
    "        \n",
    "        script = soup.find_all(\"script\")\n",
    "        if(script[22]):\n",
    "            jss =  str(script[22])\n",
    "            str_replace_qoutes = jss.replace('\\\"', '\\\\\"')\n",
    "            str_minus_semi_colon = str_replace_qoutes.replace(\";\",\" \")\n",
    "            str_minus_sdarr = str_minus_semi_colon.replace(\"sDArr\",\"\")\n",
    "            str_minus_equal = str_minus_sdarr.replace(\"=\",\"\")\n",
    "\n",
    "            #everything before sdarr\n",
    "            head, sep, tail = str_minus_equal.partition('(jsiScripsInMW,50) ')\n",
    "            #everything after sdarr\n",
    "            head2, sep2, tail2 = tail.partition('  jsiMWrefreshDelay')\n",
    "            result = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", head2)\n",
    "            arr = result.split(\"' '\")\n",
    "            arr[0] = arr[0].replace(\"\\'\",\"\")\n",
    "            arr[-1] = arr[-1].replace(\"\\'\",\"\")\n",
    "\n",
    "            sdarr = []\n",
    "            sec = []\n",
    "            count =1\n",
    "            for i in range(len(arr)):\n",
    "                count = count + 1\n",
    "                sec.append(arr[i])\n",
    "                if count ==22:\n",
    "                    count = 1\n",
    "                    sdarr.append(sec)\n",
    "                    sec =[]\n",
    "            for row in sdarr:\n",
    "                sub_row = [row[2], row[8], row[9], row[10], row[11], row[12]]\n",
    "                high_low = self.sortlist(sub_row)\n",
    "                markets.append({\"security\": row[0],\n",
    "                                \"last_price\": row[2],\n",
    "                                \"demand_qty\": row[5],\n",
    "                                \"demand_price\": row[6],\n",
    "                                \"supply_price\": row[8],\n",
    "                                \"supply_qty\": row[7],\n",
    "                                \"last_qty\": row[4],\n",
    "                                \"high\": max(high_low),\n",
    "                                \"low\": min(high_low)\n",
    "                                })\n",
    "            \n",
    "        return markets, sdarr\n",
    "\n",
    "    def sortlist(self, mylist):\n",
    "        newlist=[]\n",
    "        for item in mylist:\n",
    "            if float(item) > 0:\n",
    "                newlist.append(item)\n",
    "\n",
    "        if newlist == []:\n",
    "            newlist = [str(0.00), str(0.00)]\n",
    "        return newlist\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from ticker_data import ticker_data\n",
    "# # from market_data import market_data\n",
    "# import pytz\n",
    "# import time as tt\n",
    "# from datetime import datetime, timedelta, date, time\n",
    "# import json\n",
    "\n",
    "# #check if its a weekday\n",
    "# def is_week_day():\n",
    "#     return datetime.today().weekday() < 5\n",
    "\n",
    "# #check if it's correct time\n",
    "# def is_in_time():\n",
    "#     tz = pytz.timezone('Africa/Nairobi')\n",
    "#     nairobi_now = datetime.now(tz).time()\n",
    "#     nairobi_hour = nairobi_now.hour\n",
    "#     nairobi_minute = nairobi_now.minute\n",
    "#     set_time = time(3, 35)\n",
    "#     time_hour = set_time.hour\n",
    "#     time_minute = set_time.minute\n",
    "\n",
    "#     if nairobi_hour == time_hour and nairobi_minute == time_minute:\n",
    "#         return 1\n",
    "#     return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"crawler active\")\n",
    "# while 1:\n",
    "#     #if its weekday and correct time then crawl site\n",
    "#     if is_week_day() and is_in_time():\n",
    "#         f = open('config.json')\n",
    "#         #load configuration file\n",
    "#         config = json.load(f)\n",
    "#         t = ticker_data(config)\n",
    "#         m = market_data(config)\n",
    "#         w = wazua_data(config)\n",
    "#         r = rich_data(config)\n",
    "#         collected = 0\n",
    "#         for s in (m, t):\n",
    "#             s.login()\n",
    "#             collected = s.crawl_data()\n",
    "#             print(collected)\n",
    "#         if collected == 1:\n",
    "#             print(\"[\",datetime.now(),\" ] info collected  \")\n",
    "#             print()\n",
    "\n",
    "#             tt.sleep(300)\n",
    "#         else:\n",
    "#             print(\"[\", datetime.now(), \" ] failed \")\n",
    "#             print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker scapper initialized\n",
      "market scapper initialized\n",
      "rich scapper initialized\n",
      "logging in\n",
      "logging in\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#if we could use maps, this would be much more efficient\n",
    "data_list = []\n",
    "f = open('config_dev.json')\n",
    "config = json.load(f)\n",
    "t = ticker_data(config)\n",
    "m = market_data(config)\n",
    "#w = wazua_data(config)\n",
    "r = rich_data(config)\n",
    "\n",
    "#wazua = w.crawl_data()#[[0,1,34,566,677], [1,2,345,6785,89]]\n",
    "rich = r.crawl_data()#[[0,3242,1,4353,786], [1,23432,2,345,45]]\n",
    "ticker= t.crawl_data()#[[0,234,5756,1], [1,567567,2343,2]]\n",
    "market,m_sdarr = m.crawl_data()#[[0,345,6786,24,1], [1,24234,6456,87,2]]\n",
    "\n",
    "#data_list.append(wazua)\n",
    "data_list.append(rich)\n",
    "data_list.append(ticker)\n",
    "data_list.append(market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'percentage_change': '1.72%', 'volume': '17,500', 'current': '0.59', 'stock': 'Home Afrika Ltd', 'previous': '0.58'}\n",
      "\n",
      "{'price': '0.57', 'price_change': '-0.02', 'security': 'HAFR'}\n",
      "\n",
      "{'supply_qty': '0', 'demand_price': '0.00', 'last_qty': '500', 'high': '8.50', 'demand_qty': '0', 'low': '8.42', 'last_price': '8.50', 'supply_price': '0.00', 'security': 'FAHR'}\n"
     ]
    }
   ],
   "source": [
    "#print(data_list[0][4])\n",
    "#print()\n",
    "print(data_list[0][6])\n",
    "print()\n",
    "print(data_list[1][16])\n",
    "print()\n",
    "print(data_list[2][26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-12-ad37fa3c7395>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-ad37fa3c7395>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    data_list[3][j][3],\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "stock_list=[0,1]\n",
    "final_data=[]\n",
    "\n",
    "for j in range(len(stock_list)):\n",
    "    final_data.append([data_list[1][j][0],\n",
    "                       data_list[2][j][0]])\n",
    "                       data_list[3][j][3],\n",
    "                       #data_list[3][j][4])\n",
    "                     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-00e7810c674c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'final_data' is not defined"
     ]
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"ACCS\":{},\\n\\t\"ADSS\":{},\\n\\t\"BAMB\":{},\\n\\t\"BAT\":{},\\n\\t\"BAUM\":{},\\n\\t\"BBK\":{},\\n\\t\"BERG\":{},\\n\\t\"BOC\":{},\\n\\t\"BRIT\":{},\\n\\t\"CABL\":{},\\n\\t\"CARB\":{},\\n\\t\"CFC\":{},\\n\\t\"CFCI\":{},\\n\\t\"CG\":{},\\n\\t\"CIC\":{},\\n\\t\"CITY\":{},\\n\\t\"CMC\":{},\\n\\t\"COOP\":{},\\n\\t\"DTK\":{},\\n\\t\"ARM\":{},\\n\\t\"DTKR\":{},\\n\\t\"EABL\":{},\\n\\t\"EGAD\":{},\\n\\t\"EQT\":{},\\n\\t\"EVRD\":{},\\n\\t\"FIRE\":{},\\n\\t\"FTGH\":{},\\n\\t\"HAFR\":{},\\n\\t\"HBL\":{},\\n\\t\"HFCK\":{},\\n\\t\"I&M\":{},\\n\\t\"ICDC\":{},\\n\\t\"JUB\":{},\\n\\t\"KAPC\":{},\\n\\t\"KCB\":{},\\n\\t\"KEGN\":{},\\n\\t\"KENO\":{},\\n\\t\"KNRE\":{},\\n\\t\"KPLC\":{},\\n\\t\"KQ\":{},\\n\\t\"KUKZ\":{},\\n\\t\"KURV\":{},\\n\\t\"LIMT\":{},\\n\\t\"LKL\":{},\\n\\t\"MASH\":{},\\n\\t\"MSC\":{},\\n\\t\"NBK\":{},\\n\\t\"NIC\":{},\\n\\t\"NICR\":{},\\n\\t\"NMG\":{},\\n\\t\"NSE\":{},\\n\\t\"OCH\":{},\\n\\t\"OCHR\":{},\\n\\t\"ORCH\":{},\\n\\t\"PAFR\":{},\\n\\t\"PORT\":{},\\n\\t\"REA\":{},\\n\\t\"SASN\":{},\\n\\t\"SCAN\":{},\\n\\t\"SCBK\":{},\\n\\t\"SCOM\":{},\\n\\t\"SGL\":{},\\n\\t\"TCL\":{},\\n\\t\"TOTL\":{},\\n\\t\"TPS\":{},\\n\\t\"UCHM\":{},\\n\\t\"UNGA\":{},\\n\\t\"UTK\":{},\\n\\t\"WTK\":{},\\n\\t\"XPRS\":{},\\n\\nNotice:  Trying to get property \\'id\\' of non-object in D:\\\\MEGA\\\\htdocs\\\\OOZA\\\\app\\\\controllers\\\\admin\\\\admincontroller.php on line 20\\nnot found']\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wazua' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-0925a04f1ae6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcompany\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mall_companies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcompany\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwazua\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mall_companies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcompany\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrich\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wazua' is not defined"
     ]
    }
   ],
   "source": [
    "#companies\n",
    "\n",
    "\n",
    "\n",
    "for company in cba:\n",
    "    all_companies.append(company)\n",
    "for company in wazua:\n",
    "    all_companies.append(company[0])\n",
    "for company in rich:\n",
    "    all_companies.append(company[0])\n",
    "\n",
    "all_companies.sort()\n",
    "\n",
    "for company in all_companies:\n",
    "    json_file = json_file + \"\\\"\"+company + \"\\\": \\\"\\\",\\n\"\n",
    "print(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('response.txt','r')\n",
    "response = f.read()\n",
    "response = response.replace(\"xdrCall.JsonXSHR(\",\"\")\n",
    "response = response.split(\"^^||^\", 1)[0]\n",
    "response = response.split(\"1^^\", 1)[1]\n",
    "response = response.split(\"|\")\n",
    "stocks = []\n",
    "for stock in response:\n",
    "    stocks.append(stock.split(\"#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SCOM',\n",
       " '',\n",
       " '28.80',\n",
       " '14:58:33',\n",
       " '3800',\n",
       " '0',\n",
       " '0.00',\n",
       " '0',\n",
       " '0.00',\n",
       " '29.10',\n",
       " '29.10',\n",
       " '28.75',\n",
       " '29.00',\n",
       " '100',\n",
       " '0',\n",
       " '10.00',\n",
       " '10.00',\n",
       " 'SAFARICOM LTD',\n",
       " '0.00',\n",
       " '220300.00',\n",
       " '53']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_sdarr[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-17de2eb42e4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mm_sdarr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mall_companies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstock\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "all_companies = []\n",
    "\n",
    "for stock in m_sdarr:\n",
    "    all_companies[stock[0]]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-dbcfa0d6ff44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_companies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SCOM\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "all_companies[\"SCOM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
